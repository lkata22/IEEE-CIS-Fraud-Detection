{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:16.980983Z","iopub.execute_input":"2025-04-27T19:08:16.981225Z","iopub.status.idle":"2025-04-27T19:08:17.697840Z","shell.execute_reply.started":"2025-04-27T19:08:16.981203Z","shell.execute_reply":"2025-04-27T19:08:17.696983Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install mlflow dagshub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:17.698727Z","iopub.execute_input":"2025-04-27T19:08:17.699207Z","iopub.status.idle":"2025-04-27T19:08:32.972248Z","shell.execute_reply.started":"2025-04-27T19:08:17.699181Z","shell.execute_reply":"2025-04-27T19:08:32.971071Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow\n  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\nCollecting dagshub\n  Downloading dagshub-0.5.9-py3-none-any.whl.metadata (12 kB)\nCollecting mlflow-skinny==2.22.0 (from mlflow)\n  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\nCollecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.1)\nCollecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nCollecting appdirs>=1.4.4 (from dagshub)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nCollecting dacite~=1.6.0 (from dagshub)\n  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\nCollecting gql[requests] (from dagshub)\n  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nCollecting treelib>=1.6.4 (from dagshub)\n  Downloading treelib-1.7.1-py3-none-any.whl.metadata (1.4 kB)\nCollecting pathvalidate>=3.0.0 (from dagshub)\n  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.37.29)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nCollecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n  Downloading dagshub_annotation_converter-0.1.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.37.29)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.11.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.19.0)\nCollecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.27.0)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.1.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\nDownloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading dagshub-0.5.9-py3-none-any.whl (260 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading dacite-1.6.0-py3-none-any.whl (12 kB)\nDownloading dagshub_annotation_converter-0.1.9-py3-none-any.whl (33 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\nDownloading treelib-1.7.1-py3-none-any.whl (19 kB)\nDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, uvicorn, treelib, pathvalidate, gunicorn, graphql-core, dacite, backoff, starlette, graphql-relay, gql, graphene, fastapi, databricks-sdk, mlflow-skinny, dagshub-annotation-converter, mlflow, dagshub\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.9.2\n    Uninstalling dacite-1.9.2:\n      Successfully uninstalled dacite-1.9.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.5.9 dagshub-annotation-converter-0.1.9 databricks-sdk-0.50.0 fastapi-0.115.12 gql-3.5.2 graphene-3.4.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 pathvalidate-3.2.3 starlette-0.46.2 treelib-1.7.1 uvicorn-0.34.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import dagshub\ndagshub.init(repo_owner='lkata22',\n             repo_name='IEEE-CIS-Fraud-Detection',\n             mlflow=True)\n\nimport mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:32.974776Z","iopub.execute_input":"2025-04-27T19:08:32.975085Z","iopub.status.idle":"2025-04-27T19:08:47.896573Z","shell.execute_reply.started":"2025-04-27T19:08:32.975057Z","shell.execute_reply":"2025-04-27T19:08:47.895623Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n\nOpen the following link in your browser to authorize the client:\nhttps://dagshub.com/login/oauth/authorize?state=083d9773-08b9-4a36-bbd2-4936e2a81961&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=4cbf4e780ce2d8db709daee82fc95a6e0465da98a2a817677bc26f5e0b9b709f\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Accessing as lkata22\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as lkata22\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"lkata22/IEEE-CIS-Fraud-Detection\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"lkata22/IEEE-CIS-Fraud-Detection\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository lkata22/IEEE-CIS-Fraud-Detection initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository lkata22/IEEE-CIS-Fraud-Detection initialized!\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"### Imports\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:47.897559Z","iopub.execute_input":"2025-04-27T19:08:47.898043Z","iopub.status.idle":"2025-04-27T19:08:48.700971Z","shell.execute_reply.started":"2025-04-27T19:08:47.898017Z","shell.execute_reply":"2025-04-27T19:08:48.700057Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Memory Reducer to reduce memory usage of DataFrame","metadata":{}},{"cell_type":"code","source":"class MemoryReducer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X = reduce_mem_usage(X)\n        return X\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n            end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.702036Z","iopub.execute_input":"2025-04-27T19:08:48.702641Z","iopub.status.idle":"2025-04-27T19:08:48.713591Z","shell.execute_reply.started":"2025-04-27T19:08:48.702613Z","shell.execute_reply":"2025-04-27T19:08:48.712556Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Cleaner Class","metadata":{}},{"cell_type":"code","source":"class MissingValueHandler(BaseEstimator, TransformerMixin):\n    def __init__(self, num_strategy='median', cat_strategy='constant', fill_value='missing'):\n        self.num_strategy = num_strategy\n        self.cat_strategy = cat_strategy\n        self.fill_value = fill_value\n        self.num_impute_values = {}\n        self.cat_impute_values = {}\n        \n    def fit(self, X, y=None):\n        num_cols = [col for col in X.columns if X[col].dtype != 'object' \n                   and col not in ['isFraud', 'TransactionID']]\n        \n        if self.num_strategy == 'median':\n            for col in num_cols:\n                self.num_impute_values[col] = X[col].median()\n        elif self.num_strategy == 'mean':\n            for col in num_cols:\n                self.num_impute_values[col] = X[col].mean()\n        elif self.num_strategy == 'constant':\n            for col in num_cols:\n                self.num_impute_values[col] = 0 \n                \n        cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n        if self.cat_strategy == 'missing':\n            for col in cat_cols:\n                self.cat_impute_values[col] = 'missing'\n        elif self.cat_strategy == 'mode':\n            for col in cat_cols:\n                self.cat_impute_values[col] = X[col].mode()[0]\n        elif self.cat_strategy == 'constant':\n            for col in cat_cols:\n                self.cat_impute_values[col] = self.fill_value\n                \n        return self\n    \n    def transform(self, X, y=None):\n        for col, val in self.num_impute_values.items():\n            if col in X.columns:\n                X[col].fillna(val, inplace=True)\n                X[f'{col}_missing'] = X[col].isna().astype(int)\n                \n        for col, val in self.cat_impute_values.items():\n            if col in X.columns:\n                X[col].fillna(val, inplace=True)\n                \n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.714714Z","iopub.execute_input":"2025-04-27T19:08:48.715010Z","iopub.status.idle":"2025-04-27T19:08:48.738422Z","shell.execute_reply.started":"2025-04-27T19:08:48.714986Z","shell.execute_reply":"2025-04-27T19:08:48.737431Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Feature Engineer Class (Creates new features and transforms existing ones\n","metadata":{}},{"cell_type":"code","source":"class FeatureEngineer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.freq_encoders = {}\n        \n    def fit(self, X, y=None):\n        freq_cols = ['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']\n        for col in freq_cols:\n            if col in X.columns:\n                self.freq_encoders[col] = X[col].value_counts(dropna=False)\n        return self\n    \n    def transform(self, X, y=None):\n        if 'TransactionAmt' in X.columns:\n            for group_col in ['card1', 'card4']:\n                if group_col in X.columns:\n                    group_means = X.groupby([group_col])['TransactionAmt'].mean()\n                    X[f'TransactionAmt_to_mean_{group_col}'] = X['TransactionAmt'] / X[group_col].map(group_means)\n        \n        for col, counts in self.freq_encoders.items():\n            if col in X.columns:\n                X[f'{col}_freq'] = X[col].map(counts)\n        \n        if 'P_emaildomain' in X.columns and 'R_emaildomain' in X.columns:\n            X['P_emaildomain_match_R_emaildomain'] = (X['P_emaildomain'] == X['R_emaildomain']).astype(int)\n            \n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.739465Z","iopub.execute_input":"2025-04-27T19:08:48.739756Z","iopub.status.idle":"2025-04-27T19:08:48.761362Z","shell.execute_reply.started":"2025-04-27T19:08:48.739735Z","shell.execute_reply":"2025-04-27T19:08:48.760218Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Handles unseen categories and missing values safely","metadata":{}},{"cell_type":"code","source":"class CategoricalEncoder(BaseEstimator, TransformerMixin):\n  \n    def __init__(self, handle_unseen='impute', impute_value='missing'):\n        self.handle_unseen = handle_unseen \n        self.impute_value = impute_value\n        self.encoders = {}\n        self.known_categories = {}\n        \n    def fit(self, X, y=None):\n        cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n        for col in cat_cols:\n            unique_vals = X[col].dropna().unique()\n            self.known_categories[col] = set(unique_vals)\n            \n            le = LabelEncoder()\n            if self.handle_unseen == 'impute':\n                le.fit(np.append(unique_vals, self.impute_value))\n            else:\n                le.fit(unique_vals)\n            self.encoders[col] = le\n        return self\n    \n    def transform(self, X, y=None):\n        X = X.copy()\n        for col, le in self.encoders.items():\n            if col in X.columns:\n                X[col] = X[col].astype(str)\n                X[col] = X[col].replace('nan', self.impute_value)\n                \n                if self.handle_unseen == 'impute':\n                    unseen_mask = ~X[col].isin(self.known_categories[col])\n                    X.loc[unseen_mask, col] = self.impute_value\n                \n                try:\n                    X[col] = le.transform(X[col])\n                except ValueError:\n                    unseen = set(X[col].unique()) - set(le.classes_)\n                    X.loc[X[col].isin(unseen), col] = self.impute_value\n                    X[col] = le.transform(X[col])\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.762527Z","iopub.execute_input":"2025-04-27T19:08:48.762905Z","iopub.status.idle":"2025-04-27T19:08:48.786631Z","shell.execute_reply.started":"2025-04-27T19:08:48.762862Z","shell.execute_reply":"2025-04-27T19:08:48.785542Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Featire Selector Class (Selects features based on importance or other criteria)","metadata":{}},{"cell_type":"code","source":"class FeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, strategy='default'):\n        self.strategy = strategy\n        self.selected_features = None\n        \n    def fit(self, X, y=None):\n        if self.strategy == 'default':\n            cols_to_drop = [\n                'TransactionID', \n                'V300', 'V309', 'V111', 'V124', 'V106', 'V125', 'V315', 'V134', 'V102', 'V123', \n                'V136', 'V305', 'V110', 'V129', 'V114', 'V116', 'V298', 'V126', 'V113', 'V105', \n                'V119', 'V104', 'V122', 'V320', 'V115', 'V317', 'V303', 'V112', 'V118', 'V108', \n                'V127', 'V132', 'V109', 'V103', 'V120', 'V107', 'V131', 'V135', 'V308', 'V117', \n                'V121', 'V133', 'V130', 'V318', 'V304', 'V128', 'V319', 'V307', 'V306', 'V302', \n                'V311', 'V301', 'V310'\n            ]\n            self.selected_features = [col for col in X.columns if col not in cols_to_drop]\n            \n        return self\n    \n    def transform(self, X, y=None):\n        if self.selected_features is not None:\n            X = X.copy()\n            for col in self.selected_features:\n                if col not in X.columns:\n                    X[col] = np.nan \n            return X[self.selected_features]\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.789800Z","iopub.execute_input":"2025-04-27T19:08:48.790761Z","iopub.status.idle":"2025-04-27T19:08:48.813758Z","shell.execute_reply.started":"2025-04-27T19:08:48.790729Z","shell.execute_reply":"2025-04-27T19:08:48.812762Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Start of training","metadata":{}},{"cell_type":"code","source":"RANDOM_STATE = 42\nN_FOLDS = 5\nTEST_SIZE = 0.2\n\n\ntrain_identity = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\ntrain_transaction = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\n\n\ntrain_df = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n\nprint(f\"Training data shape: {train_df.shape}\")\nprint(f\"Fraud rate: {train_df['isFraud'].mean():.4f}\")\n\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df.drop('isFraud', axis=1),\n    train_df['isFraud'],\n    test_size=TEST_SIZE,\n    random_state=RANDOM_STATE,\n    stratify=train_df['isFraud']\n)\n\n\nprint(\"Building preprocessing pipeline...\")\npreprocessing_pipeline = Pipeline([\n    ('memory_reducer', MemoryReducer()),\n    ('missing_handler', MissingValueHandler(\n        num_strategy='median',\n        cat_strategy='constant',\n        fill_value='missing'\n    )),\n    ('feature_engineer', FeatureEngineer()),\n    ('categorical_encoder', CategoricalEncoder(\n        handle_unseen='impute',\n        impute_value='missing'\n    )),\n    ('feature_selector', FeatureSelector(strategy='default'))\n])\n\nprint(\"Preprocessing training data...\")\nX_train_preprocessed = preprocessing_pipeline.fit_transform(X_train, y_train)\nX_val_preprocessed = preprocessing_pipeline.transform(X_val)\n\nX_train_preprocessed = X_train_preprocessed.fillna(-999)\nX_val_preprocessed = X_val_preprocessed.fillna(-999)\n\nprint(\"Training Logistic Regression model...\")\n\nkf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n\ncv_scores = []\nmodels = []\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X_train_preprocessed, y_train)):\n    print(f\"\\nFold {fold + 1}/{N_FOLDS}\")\n    \n    X_tr, X_v = X_train_preprocessed.iloc[train_idx], X_train_preprocessed.iloc[valid_idx]\n    y_tr, y_v = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n    \n    model = LogisticRegression(\n        penalty='l2',\n        solver='lbfgs',  \n        max_iter=500,         \n        random_state=RANDOM_STATE,\n        n_jobs=-1         \n    )\n    \n    model.fit(X_tr, y_tr)  \n\n    val_preds = model.predict_proba(X_v)[:, 1]\n    score = roc_auc_score(y_v, val_preds)\n    cv_scores.append(score)\n    models.append(model)\n    print(f\"Fold {fold + 1} AUC: {score:.5f}\")\n\nprint(\"\\nCross-validation results:\")\nprint(f\"Mean AUC: {np.mean(cv_scores):.5f}\")\nprint(f\"Std AUC: {np.std(cv_scores):.5f}\")\n\nprint(\"\\nEvaluating on holdout validation set...\")\nval_preds = np.mean([model.predict_proba(X_val_preprocessed)[:, 1] for model in models], axis=0)\nval_score = roc_auc_score(y_val, val_preds)\nprint(f\"Validation AUC: {val_score:.5f}\")\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:08:48.814766Z","iopub.execute_input":"2025-04-27T19:08:48.815020Z","iopub.status.idle":"2025-04-27T19:32:41.104976Z","shell.execute_reply.started":"2025-04-27T19:08:48.814999Z","shell.execute_reply":"2025-04-27T19:32:41.102478Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (590540, 434)\nFraud rate: 0.0350\nBuilding preprocessing pipeline...\nPreprocessing training data...\nMem. usage decreased to 838.92 Mb (46.4% reduction)\nMem. usage decreased to 209.73 Mb (46.4% reduction)\nTraining Logistic Regression model...\n\nFold 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 AUC: 0.65313\n\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 AUC: 0.66127\n\nFold 3/5\nFold 3 AUC: 0.65838\n\nFold 4/5\nFold 4 AUC: 0.65008\n\nFold 5/5\nFold 5 AUC: 0.64437\n\nCross-validation results:\nMean AUC: 0.65345\nStd AUC: 0.00599\n\nEvaluating on holdout validation set...\nValidation AUC: 0.65578\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"\n## Feature Importance\n","metadata":{}},{"cell_type":"code","source":"\nprint(\"\\nFeature importance analysis...\")\nfeature_importance = pd.DataFrame({\n    'feature': X_train_preprocessed.columns,\n    'importance': np.mean([np.abs(model.coef_[0]) for model in models], axis=0)\n}).sort_values('importance', ascending=False)\n\n\nprint(\"\\nTop 20 features:\")\nprint(feature_importance.head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:35:17.575822Z","iopub.execute_input":"2025-04-27T19:35:17.577041Z","iopub.status.idle":"2025-04-27T19:35:17.599048Z","shell.execute_reply.started":"2025-04-27T19:35:17.577001Z","shell.execute_reply":"2025-04-27T19:35:17.597712Z"}},"outputs":[{"name":"stdout","text":"\nFeature importance analysis...\n\nTop 20 features:\n        feature  importance\n378  DeviceInfo    0.000036\n3         card1    0.000030\n782  card1_freq    0.000030\n281        V264    0.000024\n331        V332    0.000023\n282        V265    0.000022\n220        V203    0.000020\n332        V333    0.000018\n280        V263    0.000018\n291        V274    0.000017\n182        V165    0.000017\n43          D15    0.000016\n292        V275    0.000016\n318        V314    0.000016\n316        V312    0.000015\n29           D1    0.000014\n30           D2    0.000014\n32           D4    0.000013\n290        V273    0.000013\n330        V331    0.000013\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## MLFlow logging","metadata":{}},{"cell_type":"code","source":"mlflow.set_experiment(\"LR_Training\")\n\nwith mlflow.start_run(run_name=\"LR_Cleaning\"):\n    mlflow.log_param(\"memory_reduction\", True)\n    mlflow.log_param(\"missing_value_strategy_num\", \"median\")\n    mlflow.log_param(\"missing_value_strategy_cat\", \"constant_missing\")\n    mlflow.log_text(\"Used MemoryReducer and MissingValueHandler for missing values.\", \"cleaning_notes.txt\")\n\nmlflow.end_run()\n\nwith mlflow.start_run(run_name=\"LR_Feature_Engineering\"):\n    mlflow.log_param(\"feature_engineering_applied\", True)\n    mlflow.log_param(\"freq_encoding_columns\", ['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2'])\n    mlflow.log_text(\"Created TransactionAmt_to_mean features and Email domain matching.\", \"feature_engineering_notes.txt\")\n\nmlflow.end_run()\n\nwith mlflow.start_run(run_name=\"LR_Feature_Selection\"):\n    mlflow.log_param(\"feature_selection_strategy\", \"manual_drop_low_importance_V-features\")\n    mlflow.log_param(\"final_selected_features\", len(preprocessing_pipeline.named_steps['feature_selector'].selected_features))\n    mlflow.log_text(\"Dropped around 50 V-features manually based on prior EDA.\", \"feature_selection_notes.txt\")\n\nmlflow.end_run()\n\nwith mlflow.start_run(run_name=\"LR_Final_Model\") as run:\n    mlflow.log_params({\n        \"model_type\": \"LogisticRegression\",\n        \"n_folds\": N_FOLDS,\n        \"random_state\": RANDOM_STATE,\n        \"penalty\": \"l2\",\n        \"solver\": \"lbfgs\",\n        \"max_iter\": 500\n    })\n    mlflow.log_metrics({\n        \"fold_1_auc\": cv_scores[0],\n        \"fold_2_auc\": cv_scores[1],\n        \"fold_3_auc\": cv_scores[2],\n        \"fold_4_auc\": cv_scores[3],\n        \"fold_5_auc\": cv_scores[4],\n        \"mean_auc\": np.mean(cv_scores),\n        \"std_auc\": np.std(cv_scores),\n        \"validation_auc\": val_score\n    })\n\n    best_model_idx = np.argmax(cv_scores)\n    best_model = models[best_model_idx]\n    \n    final_pipeline = Pipeline([\n        ('preprocessing', preprocessing_pipeline),\n        ('model', best_model)\n    ])\n    \n    \n    mlflow.sklearn.log_model(best_model, \"best_RF_model\")\n    mlflow.sklearn.log_model(final_pipeline, \"full_pipeline\")\n\n    top_features = feature_importance.head(20).to_dict()\n    mlflow.log_dict(top_features, \"feature_importance/top_20_features.json\")\n    \n    val_preds_sample = pd.DataFrame({\n        'actual': y_val,\n        'predicted': val_preds\n    }).sample(1000)\n    mlflow.log_table(val_preds_sample, \"validation_predictions_sample.json\")\n\n    mlflow.log_text(f\"\"\"\n    - Train shape: {X_train_preprocessed.shape}\n    - Fraud rate: {y_train.mean():.4f}\n    - Best fold AUC: {cv_scores[best_model_idx]:.4f}\n    - Validation AUC: {val_score:.4f}\n    \"\"\", \"training_summary.txt\")\n\n    print(f\"Successfully logged to MLflow! Run ID: {run.info.run_id}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:36:07.399542Z","iopub.execute_input":"2025-04-27T19:36:07.399955Z","iopub.status.idle":"2025-04-27T19:36:48.955689Z","shell.execute_reply.started":"2025-04-27T19:36:07.399925Z","shell.execute_reply":"2025-04-27T19:36:48.954299Z"}},"outputs":[{"name":"stdout","text":"üèÉ View run LR_Cleaning at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7/runs/803044f5af9d41caa405fc6fd0147440\nüß™ View experiment at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7\nüèÉ View run LR_Feature_Engineering at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7/runs/2dd1dc11404c4fd99f5debd0dca6401f\nüß™ View experiment at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7\nüèÉ View run LR_Feature_Selection at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7/runs/ed5fdfee1cb84be0a504008fab6a90f4\nüß™ View experiment at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31m2025/04/27 19:36:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n\u001b[31m2025/04/27 19:36:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Successfully logged to MLflow! Run ID: dc3d4e74ef774538af150379ecb2651b\nüèÉ View run LR_Final_Model at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7/runs/dc3d4e74ef774538af150379ecb2651b\nüß™ View experiment at: https://dagshub.com/lkata22/IEEE-CIS-Fraud-Detection.mlflow/#/experiments/7\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}